
#Data Analysis with Pyhton
import pandas as pd

filename = 'https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data'

headers = ["symboling","normalized-losses","make","fuel-type","aspiration", "num-of-doors","body-style",
         "drive-wheels","engine-location","wheel-base", "length","width","height","curb-weight","engine-type",
         "num-of-cylinders", "engine-size","fuel-system","bore","stroke","compression-ratio","horsepower",
         "peak-rpm","city-mpg","highway-mpg","price"]

df1=pd.read_csv(filename, names = headers)
df1.head()


# In[34]:

##cleaning data
import numpy as np

df1.replace("?", np.nan, inplace=True)
df1.head()

#check missing data
missing_data=df1.isnull()
missing_data
# check the number of lost values
for column in missing_data.columns.values.tolist():
    print(column)
    print(missing_data[column].value_counts())
    print(" ")
    # now we can see the number of missing values in each column


# In[49]:

# Replace missing data

#replace with mean
avg1=df1['normalized-losses'].astype(float).mean(axis=0)
df1['normalized-losses'].replace(np.nan,avg1,inplace=True)

avg2=df1['bore'].astype('float').mean(axis=0)
df1['bore'].replace(np.nan,avg2,inplace=True)

avg3=df1['stroke'].astype('float').mean(axis=0)
df1['stroke'].replace(np.nan,avg3,inplace=True)

avg4=df1['horsepower'].astype('float').mean(axis=0)
df1['horsepower'].replace(np.nan,avg4,inplace=True)

avg5=df1['peak-rpm'].astype('float').mean(axis=0)
df1['peak-rpm'].replace(np.nan,avg5,inplace=True)

#replace with frequency
df1['num-of-doors'].value_counts() #count values of that column
df1['num-of-doors'].value_counts().idxmax() #calculate the most common value

#replace the missing 'num-of-doors' values by the most frequent 
df1["num-of-doors"].replace(np.nan, "four", inplace = True)

#Drop whole rows with NAN in price column
df1.dropna(subset=['price'], axis=0, inplace=True)
df.reset_index(drop = True, inplace = True) # reset index as we dropped rows
df1.head()


# In[55]:

#corrceting formats
df1.dtypes #check data types in each column

#convert data types to correct formats
df1[['bore','stroke','price','peak-rpm']]=df1[['bore','stroke','price','peak-rpm']].astype('float')
df1[['normalized-losses']]=df1[['normalized-losses']].astype('int')

## NOW we have the data cleaned and in proper format

df1.dtypes


# In[57]:

df1.head(10)


# In[60]:

## Data Strandardization , to put the data in a standard format

#convert mpg to L/100km
df1['city-L/100km']=235/df1['city-mpg']
df1['highway-L/100km']=235/df1['highway-mpg']
df1.head()




# In[61]:

#Data Normalization, Transforming the values of several varliables in similar range

# dividing the values of length and width on their max values and replacing them with the original values
df1['length'] = df1['length']/df1['length'].max()
df1['width'] = df1['width']/df1['width'].max()
df1['height']=df1['height']/df1['height'].max()
df1[["length","width","height"]].head()


# In[71]:

# Data Binning, is to classify continuous values into limited number of bins, 
#Binning is a process of transforming continuous numerical variables into discrete categorical 'bins', for grouped analysis. 

df1["horsepower"]=df1["horsepower"].astype(float, copy=True) #convert data into correct format
binwidth = (max(df1["horsepower"])-min(df1["horsepower"]))/4 # we want 4 binwidth of similar size
bins=np.arange(min(df1['horsepower']), max(df1['horsepower']), binwidth) # We build a bin array, with a minimum value to a maximum value, with bandwidth calculated above. The bins will be values used to determine when one bin ends and another begins.
bins
group_names=['High','Medium','Low'] # We set group names
df1['horsepower-binned']=pd.cut(df1['horsepower'], bins, labels=group_names, include_lowest=True)
df1[['horsepower','horsepower-binned']].head(10)


# In[73]:

# Bins Visualization

get_ipython().magic(u'matplotlib inline')
import matplotlib as plt
from matplotlib import pyplot
ax=(0,1,2)
plt.pyplot.hist(df1['horsepower'],bins=3) #Draw histogram for horepower of 3 bins

#add labels

plt.pyplot.xlabel('horsepower')
plt.pyplot.ylabel('counts')
plt.pyplot.title('Horsepower Bins')


# In[81]:

## Indicator Variables or Dummy variables
#An indicator variable (or dummy variable) is a numerical variable used to label categories. 
#They are called 'dummies' because the numbers themselves don't have inherent meaning. as fule-type; desiel and gas to 1 and 2

dummy_var1= pd.get_dummies(df1["fuel-type"]) #assign dummy variables to fule_type column and put in new df
dummy_var1.head(10)

dummy_var1.rename(columns={'fuel-type-diesel':'gas','fuel-type-diesel':'diesel'}, inplace=True) #rename column names
dummy_var1.head()

df1=pd.concat([df1,dummy_var1],axis=1) #insert dummy_var1 to df1
df1.drop('fuel-type', axis=1, inplace=True)


# In[91]:

#do the same but for aspirations column

dummyvar2=pd.get_dummies(df1['aspiration'])
dummyvar2.head()

dummyvar2.rename(columns={'asporation-type':'std','aspiration-type':'turbo'}, inplace=True)
dummyvar2.head()

df1=pd.concat([df1,dummyvar2], axis=1)
df1.head()


# In[97]:

df1=pd.concat([df1,dummyvar2], axis=1)
df1.head()


# In[98]:

# Put the clean data in new csv file

df1.to_csv('magdy_clean_data.csv')


# In[ ]:



